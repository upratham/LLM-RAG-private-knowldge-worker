{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79f973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "463cba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_documents():\n",
    "    documents = []\n",
    "    for filename in filenames:\n",
    "        folder=Path(filename).parent.name.lower()\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            documents.append({\"type\": folder, \"source\": filename, \"text\": f.read()})\n",
    "    print(f\"Loaded {len(documents)} documents\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67f4264d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 84 documents\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'type': 'research_papers',\n",
       "  'source': '../data/processed\\\\pdf_markdown\\\\research_papers\\\\Efficient Segmentation Approach for The Traceability of Breast Cancer Tissues to Improve Diagnostic Accuracy in Ultrasound Images.md',\n",
       "  'text': \"Traitement du Signal\\nVol. 42, No. 5, October, 2025, pp. 2913-2922\\nJournal homepage: http://iieta.org/journals/ts\\nEfficient Segmentation Approach for The Traceability of Breast Cancer Tissues to Improve\\nDiagnostic Accuracy in Ultrasound Images\\nPrathamesh Suhas Uravane1 , Vedant Vinay Ganthade2 , Adityaraj Sanjay Belhe3 , Mamoon Rashid4* ,\\nShakila Basheer5 , Mariyam Aysha Bivi6\\n1 Science Academy, College of Computer, Mathematical, and Natural Sciences, University of Maryland,\\nMaryland 20742, USA\\n2 Ira A. Fulton Schools of Engineering, Arizona State University, Arizona 85281, United States\\n3 Department of AI and Engineering, Wednesday Solutions, Pune 411013, India\\n4 School of Information Communication and Technology, Bahrain Polytechnic, Isa Town 33349, Bahrain\\n5 Department of Information Systems, College of Computer and Information Science, Princess Nourah bint Abdulrahman\\nUniversity, Riyadh 11671, Saudi Arabia\\n6 Department of Computer Science, College of Computer Science, King Khalid University, Abha 61421, Saudi Arabia\\nCorresponding Author Email: mamoon873@gmail.com\\nCopyright: ©2025 The authors. This article is published by IIETA and is licensed under the CC BY 4.0 license\\n(http://creativecommons.org/licenses/by/4.0/).\\nhttps://doi.org/10.18280/ts.420540 ABSTRACT\\nReceived: 19 August 2025 Breast cancer continues to be a leading concern in global health, reaching across diverse\\nRevised: 26 August 2025 populations, and requires correct detection through early intervention. This is especially the\\nAccepted: 22 September 2025 case considering the complexity of breast tissue analysis and the increasing data volumes.\\nIn this connection, emerging data aligns with the urgency in the transformation of rapid,\\nAvailable online: 31 October 2025\\nprecise interpretation of complex ultrasound images using Artificial Intelligence (AI) to\\nadvance in diagnosis and therapy. This research provides a new approach to applying\\nKeywords:\\nsegmentation in healthcare for the traceability of every breast tissue to improve diagnostic\\nmachine learning, feature extraction, deep\\naccuracy. The latest innovations of this study are in the new preprocessing pipeline with\\nlearning, breast cancer, preprocessing,\\nadvanced image preprocessing techniques of normalization, CLAHE, Gaussian Blur, and\\nsegmentation\\naugmentation to handle noise, artefacts, and muscle regions that may lead to high false\\nfavorable rates. The two state-of-the-art deep learning-based instance segmentation\\nframeworks are used, i.e., U-Net, MultiResUNet, and DeepLabV3 with a ResNet-50\\nencoder-decoder. The overall accuracy of the study achieved is 96% for all algorithms.\\nFurthermore, the segmentation results showed good agreement with Jaccard indices\\nconsistently achieving 70%. Integrating the segmentation technique into our preprocessing\\npipeline allows for providing better clinical insights, speeding up diagnosis, and elevating\\npatient care.\\n1.INTRODUCTION with a sonographer is actively involved in the successful\\ncapturing of an ultrasound image, as the reflected waves detail\\nBreast cancer is a serious global disease, and it has raised the anatomy of the breast tissue in numerous ways. This\\nconcern over several nations and communities with an therefore creates a different kind of perspective compared to\\nalarming overall statistic of more than 2.3 million new cases, X-rays or MRIs. While X-rays and MRIs depend on different\\nwith 685,000 deaths from breast cancer alone in the year 2020 forms of radiation and magnetic fields respectively, ultrasound\\n[1]. Though medical science has made certain strides to utilizes sound waves to create images with limited risks\\norchestrate hope, the immediacy of this crisis looms large, associated with using it on patients [4-6]. Oncologists,\\nmore so in regions where access to healthcare resources is representing the first line of treatment against the diagnosis of\\ndisproportionately skimpy. For example, India is a billion-plus breast cancer, very often represent hope and counsellors,\\ncountry that is suffering from an acute shortage of medical needed by patients combating this terrible disease. The\\nprofessionals. With only over 2,000 oncologists serving 10 magnitude of the problem is serious. The ratio is too\\nmillion patients [2], the skills shortage is conspicuous. imbalanced for the number of patients is concerned with the\\nSimilarly, less than 10,000 radiologists for the whole country number of oncologists and sonographers. The demands for\\npoint to the towering task of making diagnoses on time and diagnosis and care of breast cancer are so high, yet availability\\ncorrectly [3]. But the diagnosis of breast cancers is complex is at an all-time low. In such a case, the role of a sonographer,\\nand requires full acquaintance with the basic sciences of the an expert conducting ultrasound examinations, becomes\\nimaging modalities, particularly ultrasound. It plays a very highly important. However, the imbalance in patient and\\nimportant role in breast imaging, where a radiologist together workforce numbers underlines how imperative it is to look for\\n2913\\n\\nnewer ways of bridging the gap. step-by-step technique used in our novel data preprocessing\\nIn this research, ultrasound images and their corresponding pipeline.\\nmasks, that are referred to as annotations or ground truth, are (3) Integrating our pipeline with custom-tuned algorithms\\nuseful. Ultrasound is the most common imaging modality in DeepLabV3 and ResNet50, U-Net, and MultiResUNet and\\nwhich to probe for breast cancer because it can be used non- comparing the results based on the Jaccard Index Comparisons.\\ninvasively in real-time. But these images can have a subjective The rest of the paper has been organized into the following\\ninterpretation, which is where masks come in. Masks, which sections: Section 2 provides a detailed literature review.\\nare generated via fine segmentation, indicate various regions Section 3 provides the detailed methodology of the proposed\\nof interest (ROI), such as tumors in ultrasound pictures. In this segmentation technique. The experimental test and results are\\nwork, they were used as a reference or gold standard for the presented in Section 4. Finally, the paper concludes in section\\ndevelopment and validation of deep learning algorithms for 5.\\nautomated tumor detection and analysis later in this paper with\\nthe assistance of deep learning. This means that the AI model\\ncan not only correctly characterize and delimit dubious areas 2. LITERATURE REVIEW\\nin ultrasound images but also provide an exact location on\\nwhat is being primarily concerned. Deep learning may In this section, the existing works in the field of ultrasound\\nautomatically reveal the hidden important information from an images and their involvement with AI, segmentation, and\\nultrasound image beyond what a human observer would be computer vision techniques used in medical imaging, are been\\nable to distinguish. Extracted features include complex texture discussed. Several papers in this section used advanced\\npatterns that indicate malignancy and forms. By exploring medical imaging techniques to handle complex ultrasound\\nthese characteristics, the model can provide a comprehensive images. The use of an end-to-end integrated pipeline for the\\nanalysis. Particularly in medical diagnoses, the consistency of classification of breast cancer ultrasonography images has\\ndeep learning-based models is very important. It rapidly helps been used here, and the methods that are used are K Means++,\\nanalyze images and decreases inter-radiologist variation, SLIC and have also used four different transfer learning\\nelevating a higher degree of accurate diagnosis for oncologists models such as VGG16, VGG19, DenseNet121 and ResNet50\\nto promptly act upon. [7, 8] A framework with a stepwise approach for data\\nIn this work, we suggest a novel data preprocessing pipeline augmentation has been proposed along with some pre-trained\\nto facilitate segmentation for breast cancer ultrasound imaging. DarkNet-53, transfer learning, two RDE and RGW\\nAn efficient and accurate data preprocessing pipeline unlocks optimization algorithms, probability-based methods and\\nthe powerful application of different deep learning algorithms, finally, some machine learning-based classifications [9, 10].\\nincluding DeepLabV3 with ResNet-50, U-Net, and The solution to the problem of limited ultrasound labelled data\\nMultiResUNet for segmentation. Our study is based on has been solved here by producing a novel asymmetric semi-\\nultrasound images, as they serve as a safe and real-time supervised GAN (ASSGAN), utilizing two generators and a\\nmodality for imaging. It involves several key steps, such as discriminator. These generators create reliable segmentation\\nnoise reduction using Gaussian blur, applying CLAHE for guidance without labels, leveraging unlabeled data for\\ncontrast enhancement, data augmentation to increase the size effective training. Compared with fully supervised and semi-\\nof our dataset for generalization purposes, and image supervised methods on diverse datasets, including a new\\nnormalization. Starting from the raw ultrasound images up to collection, ASSGAN excels with limited labelled images,\\nthe format consumable by the algorithms mentioned above, showing promise in addressing data scarcity challenges in\\neach step in this pipeline deals with one of the issues pertaining breast ultrasound image segmentations [11].\\nto making sense out of ultrasound imaging. These The authors have created a completely automated and multi-\\nsegmentation masks, precise outlines of the tumor edge, layer process for segmenting and classifying breast lesions\\nprovide utility for improving diagnostic accuracy and clinical from ultrasound pictures. They have also compared the\\ndecision-making in breast cancer. performance of different convolutional neural network\\nDiagnosis of breast cancer segmentation is mainly relied on architectures combining network performance with the help of\\nthe precise interpretation of ultrasound images. However, an ensemble, and they are presenting a unique step of cyclic\\nmanual delineation of tumor boundaries consumes more time, mutual optimization that helps utilize classification step\\nsubjective, and prone to the inter-observer variability among results to improve segmentation outcomes [12]. The next\\nradiology experts. To underline these challenges, our study research emphasized more on ultrasonic image segmentation's\\nfocuses on the segmentation of breast tissues, which allows noise and contrast challenges. Traditional methods struggle,\\nautomated identification of tumor regions with high accuracy. but local phase-based approaches, like level set propagation\\nPrecise segmentation assists to reduce the diagnostic using local phase and orientation, show promise. Cauchy\\ninconsistencies and assists oncologists in planning kernels improve feature extraction over log-Gabor filters.\\npersonalized treatment, including surgery, chemotherapy, and Results confirm noise handling and precise boundary capture\\nradiotherapy. By connecting the technological advances of our capabilities. The prevalence of breast ultrasound (BUS) for\\npreprocessing pipeline and deep learning models with clinical cancer detection has highlighted the significance of accurate\\nresults, our approach bridges the gap between computational tumor segmentation to assist doctors and AI diagnosis systems.\\nresearch and real-world medical solutions, ultimately While U-Net is a popular choice, it often produces false-\\nimproving diagnostic accuracy and enhancing patient positive mass predictions in normal scans, a concern for\\noutcomes. routine AI-based screening. Current studies center on\\nThe main contributions of this research are: designing fine-tuned U-Net architectures, fusion of multiple-\\n(1) Proposed a segmentation approach using deep learning modal data, and alternatives to machine learning techniques\\nalgorithms to generate better segmentation masks. such as CNNs and random forests. It addresses issues relating\\n(2) This research provides a thorough explanation for every to increasing the accuracy of segmentation and to minimize\\n2914\\n\\nfalse positives in BUS images, especially for automated fibroglandular tissue, and vessels and provide critical tools for\\nscreening applications. The manuscript introduces an adaptive clinical applications. These further underline the increasing\\nregion segmentation algorithm within a Bayesian framework reliance on AI in personalized treatment for cancers [20-25].\\nthat processes noisy images. It is based on a multiresolution\\nwavelet approach, applicable to 2D and 3D data [13].\\nThe authors of this study introduced a geometric model and 3. METHODOLOGY\\ncomputational algorithm for ultrasound image segmentation.\\nIn our proposed work, we used a segmentation strategy to\\nA partial differential equation-based flow was formulated for\\nenhance the precision in the localization of tumors of breast\\nmaximum likelihood segmentation using grey-level density\\ncancer from ultrasound images. We employed three\\nprobability and smoothness constraints. The classic Rayleigh\\nalgorithms of deep learning specifically U-Net, MultiResUNet,\\nprobability distribution models grey-level behavior in\\nand DeepLabV3 along with ResNet-50 and each of them is\\nultrasound images. The flow's steady state yields optimal\\nknown for its excellence regarding complex patterns and sharp\\nsegmentation. A finite difference approximation was\\noutline of bounders in an ultrasound image. This process is\\ndeveloped and validated through some numerical experiments,\\nmade possible using an encoder-decoder architecture, which\\nand demonstrated on fetal echography and echocardiography\\nalso enables the precise localization of tumors within the\\nultrasound images. This study developed a computer-aided\\nimages and the extraction of high-level features. The precise\\ndiagnosis (CAD) system for breast mass classification using\\ndesign of a novel data preprocessing pipeline that includes\\nultrasonography. The system showed high-performance\\nmethods Gaussian blur, CLAHE, data augmentation, and\\nclassification from the use of CNN ensemble with VGG19 and\\nnormalization is important, producing more accurate\\nResNet152 models. The dataset consisted of 1536 breast\\nsegmentation results.\\nmasses: 897 malignant, 639 benign. The CAD system based\\nHowever Gaussian Blur, CLAHE, normalization and\\non CNN offered an opportunity for clinical breast cancer\\naugmentation are separately established techniques, the\\ndiagnosis. Importantly, CNN architecture was not focused on\\ninnovation lies in their combination and sequencing with\\nmasses themselves that proved crucial for accurate\\noptimization. The preprocessing pipeline starts with the\\nclassification [14].\\nGaussian Blur to reduce high frequency noise, followed by\\nRecent works related to breast cancer imaging tend to apply\\nCLAHE to enhance local contrast. Normalization helps to\\ndeep learning to the segmentation and classification of tumors\\nensure the consistency of pixel intensity distribution through\\nautomatically. A host of techniques involves the use of CNNs,\\nthe images and augmentation integrates variation to improve\\nautomation of full-image analysis, to enhance image analysis,\\nmodel generalization. Compared to conventional\\nfor ultrasound and MRI examinations. Such models aim at\\npreprocessing techniques our pipeline structure is carefully\\nimproving diagnostic accuracy by effectively segmenting\\ntuned for breast cancer ultrasound characteristics, allowing\\nbreast masses and providing support to classify them, focusing\\nmore accurate tumor boundary detection. as presented in Table\\non real-time and large-scale data processing. In addition,\\n1, the proposed preprocessing pipeline improves segmentation\\nbenchmarks for segmentation and the development of\\naccuracy from 35% to 96.7%, establishing its effectiveness,\\npreoperative assessments are indicative of an increasingly\\nnovelty and clinical relevance. A detailed explanation of how\\nembedded AI system in both the diagnostic and surgical\\nthe whole process is carried out is visualized in Figure 1.\\nplanning environment—one that fosters more personalized\\nOur research makes use of ultrasound images and their\\nmedical care [15-19]. Authors of these studies emphasized the\\nrespective segmentation masks, which can also be coined as\\nuse of deep learning and segmentation techniques in their\\nannotations. Originally, the image and mask data were\\napproaches for the purpose of enhancing breast cancer\\ncombined in the same directory for three different labels. The\\nimaging and diagnostic accuracies. Many have employed 3D\\nauthors here built an algorithm for separating the image and\\nimage segmentation, as witnessed in predictive analysis on\\ndescribed the technique as essential for organizing and\\nchemotherapy response and enhancement in analyzing MRI\\noptimizing the breast cancer ultrasound dataset. By\\nbreast tissue. Segmentation of ultrasound images makes use of\\nsystematically segregating images and corresponding masks\\nboth global and local statistical methods, with current evidence\\ninto separate directories, the technique streamlines data access\\nsuggesting a shift to more robust multi-resolution techniques.\\nand ensures data consistency. The stepwise data preparation\\nFinally, publicly available deep learning models and datasets\\nalgorithm is given in Algorithm 1.\\nadvance the research in the segmentation of breast tissue,\\nTable 1. Algorithm performance with and without using pipeline\\nPipeline Algorithm Accuracy F1-Score Jaccard Precision Recall\\nDeeplabV3+Resnet50 0.35177 0.19793 0.12234 0.12273 0.99659\\nWithout Normalization MultiResUnet 0.34240 0.19607 0.12099 0.12134 0.99674\\nUnet 0.20948 0.17227 0.10372 0.10372 1.00000\\nDeeplabV3+Resnet50 0.95761 0.77901 0.69673 0.86729 0.78945\\nWith Normalization MultiResUnet 0.95386 0.73817 0.69673 0.86431 0.73878\\nUnet 0.95650 0.67809 0.59712 0.78527 0.74600\\nDeeplabV3+Resnet50 0.95892 0.76974 0.68537 0.85848 0.77802\\nData+Normalization+Gaussian\\nMultiResUnet 0.95818 0.75359 0.67176 0.83724 0.77136\\nblur\\nUnet 0.95874 0.72032 0.63576 0.83508 0.73800\\nDeeplabV3+Resnet50 0.95929 0.77179 0.68552 0.85275 0.77854\\nData+Normalization+Gaussian\\nMultiResUnet 0.96020 0.76420 0.68558 0.88728 0.75417\\nblur+CLAHE\\nUnet 0.96017 0.72845 0.64810 0.84648 0.75781\\nDeeplabV3+Resnet50 0.96454 0.79516 0.71453 0.80500 0.85555\\nData+Normalization+Gaussian\\nMultiResUnet 0.96553 0.79380 0.71990 0.79534 0.88684\\nblur+CLAHE+Augmentation\\nUnet 0.96735 0.82284 0.74445 0.82933 0.87565\\n2915\\n\\nthe image with a Gaussian kernel, essentially averaging the\\npixel values in a localized neighborhood, authors used it to\\nleverage the drawbacks of noisy data. This feature has mainly\\ntwo purposes: first, smoothing out minor irregularities that\\nhelped the model to focus on more prominent features relevant\\nto breast cancer diagnosis. It mitigates the influence of noise\\nand fine-grained details present in ultrasound images and\\nenhances image clarity. After examining the drawbacks of the\\nnoisy data, Gaussian blur further reduced the impact of outliers\\nand extreme intensity variations that had persisted.\\nAdditionally, smoothing out minor irregularities helped the\\nmodel to focus on more prominent features relevant to breast\\ncancer diagnosis. The usage of a large kernel size (5,5) results\\nin substantial blurring effects, and kernel size influences the\\namount of smoothing required as well as data characteristics.\\nHigh-frequency noise is diminished by using a large kernel\\nsize. It also controls the amount of blurring added to the image.\\nHere, (5,5) is the size of the neighborhood in the Gaussian\\nkernel. Careful consideration was given to this parameter, as it\\nfinds out how much noise will be terminated as well as\\ninformation lost in the process. The combined Gaussian blur\\nmethod used after normalization upgrades data quality to\\nfurther initial processing, resulting in more precise and noise-\\nrobust empirical classifier performance for breast cancer\\nimage analysis relevant to clinical practice.\\n3.2 Implementing CLAHE\\nThe next process in the pipeline employed is Contrast\\nLimited Adaptive Histogram Equalization (CLAHE), which is\\none of the key techniques for improving ultrasound image\\nquality. CLAHE is contrast enhancement using adaptive\\nhistogram equalization, which modifies the image so that its\\nintensity distribution achieves a desired average local contrast\\n[6]. This method increases the effectiveness of preprocessing\\nif used together with normalization and Gaussian blur.\\nAlthough normalization aligns pixel values and Gaussian blur\\nFigure 1. Overall system representation diagram (smoothing) reduces the noise and fine details, CLAHE\\naddresses the problems of intensity variations caused by a\\nAlgorithm 1. Stepwise Data Preparation algorithm machine and uneven illumination, particularly apparent in\\nultrasound images. This stage increases the prominence of\\nboth fine and subtle features in the images by spreading pixel\\nInput: Directory path containing raw image and mask data.\\nvalues with the aim to allow more efficient image analysis.\\nOutput: Separated directories for images and masks.\\nCLAHE, along with normalization and Gaussian blur,\\n1. Initialize variable path with the path of the data directory.\\nencompasses an entire method to enhance ultrasound images\\n2. Initialize counter counter with a value of 1.\\nby accentuating salient diagnostic features of the image and\\n3. While there are images and masks to process:\\nfacilitating their accurate identification in breast cancer\\nConstruct image_path using path, class_names, and counter:\\ncharacteristics detection. CLAHE also covers the uniform\\nimage_path=path+class_names+counter_value.png\\nblurring effect caused by excessive usage of Gaussian blur,\\nConstruct mask_path using path, class_names, counter, and\\nresulting in losing fine details and edges that are very\\nmask:\\nimportant in the segmentation purposes. Enhancing local\\nmask_path=path+class_names+counter_mask.png\\ncontrast and mitigating over usage of noise, a more balanced\\n4. Read the image from image_path and the mask from\\nway of pixel redistribution occurs across the image.\\nmask_path.\\n5. Create two separate directories to store images and masks.\\n3.3 Data augmentation\\n6. Store the image in the image’s directory and the mask in the\\nmask’s directory.\\nThe authors integrated data augmentation into the breast\\n7. Increment the counter value.\\ncancer ultrasound image segmentation pipeline to overcome\\n8. Repeat steps 3 to 7 until all images and masks are processed.\\nchallenges posed by limited datasets and enhance their model's\\nperformance. Data augmentation involves introducing\\n3.1 Noise reduction through gaussian blur\\ncontrolled variations to the pre-processed ultrasound images\\nthrough techniques of flips and rotations. By doing so, we\\nThe subsequent step in the pipeline, Gaussian blur, was\\naimed to address multiple critical goals.\\nintroduced as one of the critical preprocessing techniques. As\\n(1) We achieved a better pixel-wise representation with\\nGaussian blur is a filtering process that involves convolving\\n2916\\n\\nspiculated mass not just at the centroids but also by by our optimized preprocessing pipeline, guarantees reliable\\naugmenting images to reflect real-life variations during image segmentation performance, as illustrated by the notable\\nacquisition and resulting in different angles for the learning of enhancement in Jaccard indices and accuracy metrics reported\\nthe model. in Section 4. Figure 2 provides a much more explicit\\n(2) The model was made less sensitive to variations because explanation of how encoder-decoder architecture seems to be\\nit was trained on features extracted from images that simulated working.\\nvarious conditions like real-world imaging scenarios. Also, the\\nmodel was saved from overfitting, which is a risk of failing to\\ngeneralize to new data because it only remembers instances\\ninstead of learning how to setup rules based on standard\\nexamples.\\n(3) The identified augmented dataset improved the model\\ngeneralization over different image variations, which is\\nfundamental for a reliable breast cancer diagnosis. The authors\\nthen constructed a data augmentation training strategy that\\nincorporated data augmentation into their work to achieve\\noptimal generalizations of identifying key breast cancer\\ncharacteristic behavior from MRI in a range of images.\\nFigure 2. Working of encoder and decoder architecture\\n3.4 Normalizing data\\nNormalization is an important part of data preprocessing, as 4. RESULTS\\nit has increased the utility of the ultrasound image data for\\nfurther analysis. Pixel values are scaled to a unified range In this section, a novel preprocessing pipeline incorporating\\nbetween 0 and 1. Uniformity in pixel values in images was a a wide variety of deep learning algorithms has achieved an\\nmajor task in the context of breast cancer ultrasound images accuracy of up to 96%. We present their findings through a\\nhaving varying intensity levels. This process balanced the combination of graphical representations, evaluation metrics,\\nscale of information within each image. Outliers in very high and visual figures illustrating the disparities between actual\\nextreme intensities could easily skew the model training. The and predicted segmentation masks. The processes Gaussian\\nauthors have worked on taking away the differences in pixel blur, CLAHE, augmentation, and normalization were carried\\nrange, which in turn helps models such as DeepLabV3 and out extensively and methodically to unveil the pivotal role of\\nResNet50, MultiResNet, and Unet converge significantly the novel pipeline in enhancing model performance. The\\nwhen training. As a result, the models can identify relevant impact of each deployed technique is systematically\\nfeatures in the images more accurately and generally. The scrutinized by the authors, which gives insights about how\\npipeline used normalization to lay a consistent foundation for they contribute to improve results collectively. The\\nsubsequent techniques of segmentation. This alignment of data comprehensive research reveals the enhancement in quality of\\ncharacteristics allows models to focus on meaningful patterns segmentation achieved with the integration of the pipeline. In\\nwithin images, resulting in more robust and accurate breast general, the results section is indeed an intensive study with\\ncancer diagnostic outcomes. great depths of understanding that covers the trend of results\\nobtained using various techniques and the progressive\\n3.5 Deep learning algorithms for segmentation refinement incorporated due to the new data preprocessing\\npipeline.\\nIn this study, we used three advanced deep learning\\narchitectures U-Net, MultiResUNet, and 4.1 Experimental setup\\nDeepLabV3+ResNet50 selected based on their performance in\\nmedical image segmentation and their additional strengths. U- Experiments were implemented on a system with an\\nNet was used as the baseline model because of its all-round NVIDIA GeForce RTX 3050 GPU (4GB VRAM) and an\\nadoption in medical imaging and its ability to accurately AMD Ryzen 7 6800H CPU. The dataset was sub divided into\\ncapture both low-level and high-level features using an 70% training, 15% validation, and 15% testing, and 5-fold\\nencoder-decoder architecture. MultiResUNet, an extension of cross-validation was performed to examine robustness.\\nU-Net, comes with multi-resolution convolutional blocks that Models were trained using the Adam optimizer with a learning\\nallow the network to extract fine-grained texture patterns, rate of 1e-3, a batch size of 6, and 60 epochs. A combined\\nmaking it particularly effective for identifying small lesions Binary Cross-Entropy and Dice loss was used, with early\\nand subtle breast tissue variations in ultrasound images. The stopping (patience=20) and a ReduceLROnPlateau scheduler\\narchitecture of DeepLabV3+ResNet50, allows to detect non (factor=0.1, patience=9, min_lr=1e-7) to overcome overfitting.\\nsimilar tumor regions while maintaining boundary precision. To overcome on generalization, we integrated data\\nThe integration of these three models comes up with a augmentation: Horizontal Flip (p=1.0), Vertical Flip (p=1.0),\\ncomprehensive framework for performance comparison. This and Rotation (limit=±45°, p=1.0). This scaled the dataset 4\\ndiversity allows us to evaluate segmentation performance times and integrated the variation in dataset. For noise\\nunder different complexities of breast ultrasound images. The reduction, Gaussian Blur with a kernel size of (5,5) was\\nencoder-decoder architectures used in the networks of these applied to suppress high-frequency noise while securing tumor\\nmodels efficiently extract image features through the encoder boundaries. A fixed random seed (42) was used to certify\\nand reconstruct accurate segmentation maps through the reproducibility across dataset splitting, augmentation, and\\ndecoder. The strategic selection these architectures, supported training.\\n2917\\n\\n4.2 Results without pre-processing score of 0.12, that underscores the inadequacy of the initial\\nmodel performance for the given breast cancer ultrasound\\nIn Figure 3, the breast cancer image segmentation dataset image segmentation problem.\\nhas been subjected to the DeepLabV3+ResNet50 algorithm by The initial segmentation results from the chosen algorithms\\nthe authors without applying pre-processing to the dataset. without the use of our preprocessing pipeline resulted in poor\\nThus, the algorithm is drawn to the raw image data which performance. The natural reasons can be attributed to these\\nappears to be the case from the output the algorithm is giving. inherent complexities in ultrasound images, such as the\\nThe output is sub-optimal. The values of its accuracy and presence of noise and generally poor contrast along with\\nJaccard Scores are also very low. significant variations in both texture and intensity. Because of\\nSimilarly, if we check the performance of MultiResUNet, such complexities, the algorithms get confused, and thus it\\nand Unet in Figures 4 and 5 respectively, we can say that becomes challenging for them to accurately demarcate the\\nwithout using the data preprocessing pipeline, we cannot boundaries of the tumor. Without preprocessing, the\\nachieve better results for the segmentation. algorithms used may not be able to extract as good features\\nand reduce noise as much. In this case, segmentation masks\\nproduced would be less accurate and their overall performance\\nwould be lower Jaccard scores.\\nHowever, promisingly, the coming sections hold the\\npromise of unveiling how such initial results are transformed\\nby this preprocessing pipeline. The authors demonstrate\\nimpact on improvement in terms of accuracy and other means\\nof evaluation, thus shedding light on transformation from\\nFigure 3. Segmentation using DeepLabV3+ResNet50 modest outcomes to refined and more accurate segmentation\\nwithout using the pipeline results while promising tangible improvement in the challenge\\nof confronting this complex medical image segmentation task.\\n4.3 Results with pre-processing\\nWe successfully merged our novel data preprocessing\\npipeline into our workflow to understand the initial set of\\nchallenges and improve our segmentation results. We began\\nthis process with analysing noise reduction—a crucial step in\\nimproving the accuracy of our masks. We expect a progressive\\nFigure 4. Segmentation using MultiResUnet without using improvement in the quality and precision of our breast cancer\\npipeline tumor segmentations as we progressively add each part of the\\npipeline that includes noise reduction, contrast enhancement,\\ndata augmentation, and normalization. This systematic process\\nshall increasingly improve our results and the performances of\\nour deep learning algorithms as we advance with each stage of\\nthis preprocessing pipeline.\\nFigure 5. Segmentation using Unet without using pipeline\\nFigure 7. Noise reduction using Gaussian blur on an image\\nFigure 6. Training and validation accuracy graph for the\\nDeepLabv3+ResNet50 algorithm Figure 8. CLAHE on the denoised ultrasound image\\nThe obtained training accuracy of 35%, as shown in Figure The results shown in Figure 7 are using the Gaussian blur\\n6, along with precision and Jaccard indexes are both at a mere noise reduction technique, and it provides improved results.\\n2918\\n\\nThe pipeline's first preprocessing step is Gaussian blur, which mapped to be between about the same range; in no case does\\nstarts to progressively enhance the quality of the results of the pixel intensities in individual images dominate the training\\nsegmentation. Noise in ultrasound images starts to be sorted due to variance resulting from differences in illumination. This\\nout through this stage, which is obviously quite critical, minimizes effects due to variance in illumination conditions\\nparticularly with breast cancer ultrasounds, which are known and increases the degree to which the model will generalize\\nfor intricate details and subtle changes. For making the image patterns related to breast cancer features in different images.\\nmore stable and visually coherent, the Gaussian blur feature The overall effect of the whole preprocessing pipeline is a\\nsmoothes sharp transitions and tends to minimize noise- significant advancement in segmentation research. The\\ninduced inconsistencies. Although this is the first step ahead pipeline systematically handles inherent challenges created by\\nin the more complex process, the improvement has set a base breast cancer ultrasound images, ranging from noise and low\\non which subsequent stages are built to further enhance the contrast to minimal tissue appearance variations. With\\nprecision of the segmentation task. techniques such as sequence Gaussian blur, CLAHE,\\nFuture elements of this preprocessing pipeline involve the augmentation, and normalization, the pipeline processes raw\\nusage of CLAHE and how the application of this technique images toward a standardized dataset. This fined dataset is\\nwould subsequently increase the chances of better used to train some sophisticated deep learning models such as\\nsegmentation results, as in Figure 8. The improvement marked DeepLabV3 and ResNet-50 that permits them to capture\\nin the predicted image mask can be attributed to the fact that minute features that are fundamental to accurate\\nCLAHE could preserve and highlight the required features segmentations. In Table 2, every highlight of the algorithms\\nbetter for accuracy in segmentation results. This keeps the performs within the pipeline. Also, we are comparing the\\nlocal improvement provided by CLAHE to preserve the numerical results of every algorithm performing under every\\ndependencies between the various constituents of an image stage of our pipeline, which is shown in Figures 11-13.\\nand thereby provide the original ground truth mask with more\\nfaithful segmentations. Hence, this improvement speaks well\\nfor the effectiveness of CLAHE in adapting to the subtleties of\\nmedical images in producing better reliability and accuracy in\\ntheir segmentations.\\nThe obtained results with the second part of the pipeline\\ninvolving augmentation. Figure 9 shows the involvement of\\nthis phase and how augmentation helps segmentation achieve\\nbetter results. Introducing variations in the form of horizontal\\nand vertical flips and many other operations have helped\\nFigure 9. Augmented segmented mask\\ngenerate better data to accompany the original data and help\\nalgorithms to train these sets altogether. This makes the model\\nmore resilient to variations of several imaging conditions,\\npatient poses, and probe orientations, and ultimately leads to a\\nmore generalized segmentation model. Augmentation further\\nreduces the threat of overfitting—an ordinary issue in\\noperating with limited medical imaging datasets. By\\nintroducing controlled variations, the model learned to extract\\nand prioritize salient features regardless of minor image\\nalterations, and finally, arriving at the final stage of the\\npipeline. Figure 10 shows how normalizing pixel values helps\\nFigure 10. Final Segmentation results after the use of the\\nour model generate better masks.\\npreprocessing pipeline\\nNormalization improves training since pixel values are\\nFigure 11. Performance of DeepLabV3+ResNet50 with the pipeline\\n2919\\n\\nFigure 12. Performance of MultiResUnet with the pipeline\\nFigure 13. Performance of Unet with the pipeline\\nTable 2. Comparison of state-of-the-art segmentation methods and proposed method on breast ultrasound images\\nResearch Work /Paper Title Model/Technique Result Year\\n0.9674 (Acuuracy)\\nYour Best Model (Proposed) UNet+Gaussian+CLAHE +Augmentation 2025\\n0.74 (Jaccard)\\nDBU-Net: Dual branch U-Net [26] U2-MNet 0.9378 (Acuuracy) 2023\\nAAU-net [27] Adaptive Attention U-Net 0.6910 (Jaccard) 2022\\nAttention U-Net [28] CNN-based Segmentation 0.9500 (Acuuracy) 2024\\nTable 1 presents the segmentation performance of the three The proposed preprocessing pipeline plays a vital role in\\narchitectures evaluated in this study. Notably U-Net attained achieving these results. Prior to preprocessing, segmentation\\nthe highest accuracy (96.7%) with the complete preprocessing accuracy was limited (35.1% for DeepLabV3+ResNet50, 34.2%\\npipeline, proving its strong resilience and efficient encoder- for MultiResUNet, 20.9% for U-Net) primarily caused by\\ndecoder structure for ultrasound image segmentation. The noise, poor contrast, and complex textures in ultrasound\\nsecond evaluated architecture MultiResUNet achieved 96.5% images. Performing normalization improved performance to\\ndue to its multi-resolution convolutional blocks, which acquire roughly 95% throughout all models by fortifying pixel\\nsubtler structural details efficiently. The final architecture intensities. Gaussian blur further helps to refine accuracy by\\nDeepLabV3+ResNet50 achieved 96.4% accuracy for suppressing high-frequency noise, while CLAHE boosts local\\nextracting multi-scale contextual features by leveraging atrous contrast and tumor boundary visibility, achieving 96.73%\\nspatial pyramid pooling (ASPP). Although three architectures accuracy. These results confirm that the pipeline significantly\\naided from advanced preprocessing, the results suggest that U- enhances segmentation performance across diverse\\nNet demonstrates better for heterogeneous ultrasound data. architectures.\\n2920\\n\\nTable 2 provides a comparison between existing state-of- Ultrasonics, 65: 51-58.\\nthe-art segmentation methods for breast ultrasound images and https://doi.org/10.1016/j.ultras.2015.10.023.\\nour proposed pre-processing pipeline. This highlights the [6] Hesaraki, S., Mohammed, A.S., Eisaei, M., Mousa, R.\\nsignificant performance improvement achieved through our (2025). Breast cancer ultrasound image segmentation\\noptimized pipeline. using improved 3DUnet++. WFUMB Ultrasound Open,\\n3(1): 100068.\\nhttps://doi.org/10.1016/j.wfumbo.2024.100068\\n5. CONCLUSION [7] National Breast Cancer Foundation. Breast cancer\\nultrasound. https://nbcf.org.au/about-breast-\\nIn this study, we developed a novel preprocessing pipeline cancer/detection-and-awareness/breast-cancer-\\nthat contains Gaussian blur, CLAHE, normalization, and ultrasound/.\\naugmentation to enhance segmentation accuracy for breast [8] Wu, G.G., Zhou, L.Q., Xu, J.W., Wang, J.Y., Wei, Q.,\\nultrasound images. By integrating this optimized Deng, Y.B., Cui, X.W., Dietrich, C.F. (2019). Artificial\\npreprocessing techniques with three state-of-the-art deep intelligence in breast ultrasound. World Journal of\\nlearning models U-Net, MultiResUNet, and Radiology, 11(2): 19-26.\\nDeepLabV3+ResNet50, we achieved prominent https://doi.org/10.4329/wjr.v11.i2.19\\nimprovements in diagnostic precision. Our approach obtained [9] Inan, M.S.K., Alam, F.I., Hasan, R. (2022). Deep\\na segmentation accuracy of 96.7% and a Jaccard index of 0.74, integrated pipeline of segmentation guided classification\\noutperforming several existing methods and demonstrating the of breast cancer from ultrasound images. Biomedical\\nclinical relevance of our method for tumor traceability. Signal Processing and Control, 75: 103553.\\nDespite these promising results, we admit certain https://doi.org/10.1016/j.bspc.2022.103553\\nlimitations of proposed study. The proposed approach requires [10] Nasser, M., Yusof, U.K. (2023). Deep learning based\\nadditional computational costs due to the multi-step methods for breast cancer diagnosis: A systematic review\\npreprocessing. In addition, challenging cases such as small and future direction. Diagnostics, 13(1): 161.\\ntumors, heterogeneous tissue textures, and low-contrast https://doi.org/10.3390/diagnostics13010161\\nultrasound images remain challenging to segment with high [11] Jabeen, K., Khan, M.A., Alhaisoni, M., Tariq, U., Zhang,\\nprecision. Y.D., Hamza, A., Mickus, A., Damaševičius, R. (2022).\\nThere exists a future scope for implementing high Breast cancer classification from ultrasound images\\nperformance and enhanced preprocessing stages, lightweight using probability-based optimal deep learning feature\\ndeep learning networks which requisite lesser computation and fusion. Sensors, 22(3): 807.\\nleveraging attention-based hybrid models to improve https://doi.org/10.3390/s22030807\\nsegmentation accuracy. Overall, our results illustrate that the [12] Martinez, R.G., Van Dongen, D.M. (2023). Deep\\nproposed framework significantly enhances segmentation learning algorithms for the early detection of breast\\naccuracy and offers a strong foundation for advancing cancer: A comparative study with traditional machine\\ncomputer-assisted breast cancer diagnostic. learning. Informatics in Medicine Unlocked, 41: 101317.\\nhttps://doi.org/10.1016/j.imu.2023.101317\\n[13] Zhai, D., Hu, B., Gong, X., Zou, H., Luo, J. (2022). ASS-\\nFUNDING GAN: Asymmetric semi-supervised GAN for breast\\nultrasound image segmentation. Neurocomputing, 493:\\nThis research is supported by Princess Nourah bint 204-216. https://doi.org/10.1016/j.neucom.2022.04.021\\nAbdulrahman University Researchers Supporting Project [14] Abo-El-Rejal, A., Ayman, S., Aymen, F. (2024).\\nnumber (PNURSP2025R195), Princess Nourah bint Advances in breast cancer segmentation: A\\nAbdulrahman University, Riyadh, Saudi Arabia. comprehensive review. Acadlore Transactions on AI and\\nMachine Learning, 3(2): 70-83.\\nhttps://doi.org/10.56578/ataiml030201\\nREFERENCES [15] Podda, A.S., Balia, R., Barra, S., Carta, S., Fenu, G.,\\nPiano, L. (2022). Fully-automated deep learning pipeline\\n[1] World Health Organization. Breast cancer. for segmentation and classification of breast ultrasound\\nhttps://www.who.int/news-room/fact- images. Journal of Computational Science, 63: 101816.\\nsheets/detail/breast-cancer. https://doi.org/10.1016/j.jocs.2022.101816\\n[2] Mehrotra, R., Yadav, K. (2022). Breast cancer in India: [16] Bilic, A., Chen, C. (2024). BC-MRI-SEG: A breast\\nPresent scenario and the challenges ahead. World Journal cancer MRI tumor segmentation benchmark. In 2024\\nof Clinical Oncology, 13(3): 209-218. IEEE 12th International Conference on Healthcare\\nhttps://doi.org/10.5306/wjco.v13.i3.209 Informatics (ICHI), Orlando, USA, pp. 674-678.\\n[3] Kalyanpur, A. (2008). Commentary 3-radiology in India: https://doi.org/10.1109/ICHI61247.2024.00107\\nThe next decade. Indian Journal of Radiology and [17] Belaid, A., Boukerroui, D., Maingourd, Y., Lerallut, J.F.\\nImaging, 18(3): 191-192. https://doi.org/10.4103/0971- (2010). Phase-based level set segmentation of ultrasound\\n3026.41869 images. IEEE Transactions on Information Technology\\n[4] U.S. Food and Drug Administration. Ultrasound imaging. in Biomedicine, 15(1): 138-147.\\nhttps://www.fda.gov/radiation-emitting- https://doi.org/10.1109/TITB.2010.2090889\\nproducts/medical-imaging/ultrasound-imaging. [18] Chen, M., Xing, J., Guo, L. (2024). MRI-based deep\\n[5] Gu, P., Lee, W., Roubidoux, M.A., Yuan, J., Wang, X., learning models for preoperative breast volume and\\nCarson, P.L. (2015). Automated 3D ultrasound image density assessment assisting breast reconstruction.\\nsegmentation to aid breast cancer image interpretation. Aesthetic Plastic Surgery, 48(23): 4994-5006.\\n2921\\n\\nhttps://doi.org/10.1007/s00266-024-04074-2 learning model and dataset for segmentation of breast,\\n[19] Zhang, S., Liao, M., Wang, J., Zhu, Y., Zhang, Y., Zhang, fibroglandular tissue, and vessels in breast MRI.\\nJ., Zheng, R., Lv, L., Zhu, D., Chen, H., Wang, W. (2023). Scientific Reports, 14(1): 5383.\\nFully automatic tumor segmentation of breast ultrasound https://doi.org/10.1038/s41598-024-54048-2\\nimages with deep learning. Journal of Applied Clinical [24] Sarti, A., Corsi, C., Mazzini, E., Lamberti, C. (2005).\\nMedical Physics, 24(1): e13863. Maximum likelihood segmentation of ultrasound images\\nhttps://doi.org/10.1002/acm2.13863 with Rayleigh distribution. IEEE Transactions on\\n[20] Ranjitha, K.V., Pushphavathi, T.P. (2024). Improving Ultrasonics, Ferroelectrics, and Frequency Control,\\nprediction accuracy for neo-adjuvant chemotherapy 52(6): 947-960.\\nresponse in breast cancer through 3D image https://doi.org/10.1109/TUFFC.2005.1504017\\nsegmentation and deep learning techniques. Artificial [25] Tanaka, H., Chiu, S.W., Watanabe, T., Kaoku, S.,\\nIntelligence in Medicine, 137-162. Yamaguchi, T. (2019). Computer-aided diagnosis\\nhttps://www.taylorfrancis.com/chapters/edit/10.1201/97 system for breast ultrasound images using deep learning.\\n81003369059-12/improving-prediction-accuracy-neo- Physics in Medicine & Biology, 64(23): 235013.\\nadjuvant-chemotherapy-response-breast-cancer-3d- https://doi.org/10.1088/1361-6560/ab5093\\nimage-segmentation-deep-learning-techniques-ranjitha- [26] Pramanik, P., Pramanik, R., Schwenker, F., Sarkar, R.\\npushphavathi. (2023). DBU-Net: Dual branch U-Net for tumor\\n[21] Boukerroui, D., Baskurt, A., Noble, J.A., Basset, O. segmentation in breast ultrasound images. Plos One,\\n(2003). Segmentation of ultrasound images- 18(11): e0293615.\\nmultiresolution 2D and 3D algorithm based on global and https://doi.org/10.1371/journal.pone.0293615\\nlocal statistics. Pattern Recognition Letters, 24(4-5): 779- [27] Chen, G., Li, L., Dai, Y., Zhang, J., Yap, M.H. (2022).\\n790.https://doi.org/10.1016/S0167-8655(02)00181-2 AAU-net: An adaptive attention U-net for breast lesions\\n[22] Forghani, Y., Timotoe, R., Figueiredo, M., Marques, T., segmentation in ultrasound images. IEEE Transactions\\nBatista, E., Cordoso, F., Cardoso, M.J., Santinha, J., on Medical Imaging, 42(5): 1289-1300.\\nGouveia, P. (2024). Breast tissue segmentation in MR https://doi.org/10.1109/TMI.2022.3226268\\nimages using deep-learning. European Journal of Cancer, [28] Lu, Y.M. (2024). Breast ultrasound image segmentation\\n200(S1): 113876. based on attention U-Net. In Proceedings of the 2nd\\nhttps://doi.org/10.1016/j.ejca.2024.113876 International Conference on Machine Learning and\\n[23] Lew, C.O., Harouni, M., Kirksey, E.R., Kang, E.J., Dong, Automation, CONF-MLA 2024, Adana, Turkey.\\nH., Gu, H., Grimm, L.J., Walsh, R., Lowell, D.A., https://doi.org/10.4108/eai.21-11-2024.2354629\\nMazurowski, M.A. (2024). A publicly available deep\\n2922\"}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents=fetch_documents()\n",
    "documents[34:35]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-rag-private-knowledge-worker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

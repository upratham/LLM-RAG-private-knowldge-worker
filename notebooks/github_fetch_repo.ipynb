{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87ee78cf",
   "metadata": {},
   "source": [
    "# GitHub Repository Documentation Generator with OpenAI SDK\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "This notebook uses the OpenAI SDK with the open-source `gpt-oss-120b` model to generate repository documentation.\n",
    "\n",
    "1. **Get OpenAI API Key** from https://platform.openai.com/api-keys\n",
    "2. **Set environment variable**: `OPENAI_API_KEY=your_token_here` (already in .env file)\n",
    "3. **Run the cells below** to generate documentation\n",
    "\n",
    "The default model is `openai/gpt-oss-120b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbca8225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import base64\n",
    "import pathlib\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dcf76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_USERNAME = os.getenv(\"GITHUB_USERNAME\", \"\").strip()\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\", \"\").strip() \n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\").strip()  # required\n",
    "MODEL_NAME = \"gpt-4.1-nano\"\n",
    "OUT_DIR = pathlib.Path(\"../data/processed/repo_summaries\").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5ac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MAX_TREE_ITEMS = 800\n",
    "MAX_FILE_CHARS = 12000\n",
    "MAX_SOURCE_FILES = 12\n",
    "WORKERS=10\n",
    "\n",
    "IMPORTANT_FILES = [\n",
    "    \"README.md\", \"README.MD\", \"README.rst\",\n",
    "    \"pyproject.toml\", \"requirements.txt\", \"Pipfile\", \"setup.py\",\n",
    "    \"package.json\", \"pnpm-lock.yaml\", \"yarn.lock\", \"package-lock.json\",\n",
    "    \"Cargo.toml\", \"go.mod\", \"pom.xml\", \"build.gradle\", \"build.gradle.kts\",\n",
    "    \"Dockerfile\", \"docker-compose.yml\",\n",
    "    \".env.example\", \".github/workflows\",\n",
    "    \"Makefile\", \"compose.yaml\",\n",
    "]\n",
    "\n",
    "SOURCE_EXTS = {\n",
    "    \".py\", \".js\", \".ts\", \".tsx\", \".java\", \".kt\", \".go\", \".rs\", \".cpp\", \".c\", \".h\", \".hpp\",\n",
    "    \".cs\", \".php\", \".rb\", \".swift\", \".scala\", \".lua\", \".sql\", \".sh\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ec2873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gh_headers():\n",
    "    h = {\"Accept\": \"application/vnd.github+json\"}\n",
    "    if GITHUB_TOKEN:\n",
    "        h[\"Authorization\"] = f\"Bearer {GITHUB_TOKEN}\"\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bed39af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gh_get(url, params=None):\n",
    "    r = requests.get(url, headers=gh_headers(), params=params, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32554a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_repos(username):\n",
    "    \"\"\"Fetch all repos using pagination (100 per page).\"\"\"\n",
    "    repos = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        batch = gh_get(\n",
    "            f\"https://api.github.com/users/{username}/repos\",\n",
    "            params={\"per_page\": 100, \"page\": page, \"sort\": \"updated\"}\n",
    "        )\n",
    "        if not batch:\n",
    "            break\n",
    "        repos.extend(batch)\n",
    "        page += 1\n",
    "    return repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457e10ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_branch(repo_full_name, fallback=\"main\"):\n",
    "    repo = gh_get(f\"https://api.github.com/repos/{repo_full_name}\")\n",
    "    return repo.get(\"default_branch\") or fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2e62d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_tree(repo_full_name, branch):\n",
    "    \"\"\"\n",
    "    Two-step process: get commit SHA from branch ref, then fetch full recursive tree.\n",
    "    \"\"\"\n",
    "    ref = gh_get(f\"https://api.github.com/repos/{repo_full_name}/git/refs/heads/{branch}\")\n",
    "    sha = ref[\"object\"][\"sha\"]\n",
    "    \n",
    "    tree = gh_get(\n",
    "        f\"https://api.github.com/repos/{repo_full_name}/git/trees/{sha}\",\n",
    "        params={\"recursive\": 1}\n",
    "    )\n",
    "    return tree.get(\"tree\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9884705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_probably_binary(path):\n",
    "    \"\"\"Check file extension against known binary formats.\"\"\"\n",
    "    return any(path.lower().endswith(ext) for ext in [\n",
    "        \".png\", \".jpg\", \".jpeg\", \".gif\", \".webp\",\n",
    "        \".pdf\", \".zip\", \".gz\", \".7z\",\n",
    "        \".mp4\", \".mov\", \".avi\",\n",
    "        \".exe\", \".dll\", \".so\", \".dylib\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c00542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_file_text(repo_full_name, path, branch):\n",
    "    \"\"\"\n",
    "    GitHub API returns file content base64-encoded.\n",
    "    Decode and handle both UTF-8 and Latin-1 encodings.\n",
    "    \"\"\"\n",
    "    data = gh_get(\n",
    "        f\"https://api.github.com/repos/{repo_full_name}/contents/{path}\",\n",
    "        params={\"ref\": branch}\n",
    "    )\n",
    "    \n",
    "    if isinstance(data, dict) and data.get(\"type\") == \"file\":\n",
    "        content = data.get(\"content\", \"\")\n",
    "        if data.get(\"encoding\") == \"base64\" and content:\n",
    "            raw = base64.b64decode(content.encode(\"utf-8\", errors=\"ignore\"))\n",
    "            try:\n",
    "                txt = raw.decode(\"utf-8\", errors=\"replace\")\n",
    "            except Exception:\n",
    "                txt = raw.decode(\"latin-1\", errors=\"replace\")\n",
    "            return txt[:MAX_FILE_CHARS]\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d24758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_key_files(tree_paths):\n",
    "    \"\"\"\n",
    "    Multi-stage file selection:\n",
    "    1. Important files (README, config, CI/CD)\n",
    "    2. Source code files sorted by depth\n",
    "    3. Deduplicate while preserving order\n",
    "    \"\"\"\n",
    "    picked = []\n",
    "    \n",
    "    for imp in tqdm(IMPORTANT_FILES, desc=\"Finding important files\"):\n",
    "        for p in tree_paths:\n",
    "            if p == imp or p.endswith(\"/\" + imp) or (imp.endswith(\"/\") and p.startswith(imp)):\n",
    "                picked.append(p)\n",
    "\n",
    "    src = [p for p in tree_paths if pathlib.Path(p).suffix in SOURCE_EXTS and not is_probably_binary(p)]\n",
    "    src.sort(key=lambda x: (x.count(\"/\"), len(x)))\n",
    "    picked.extend(src[:MAX_SOURCE_FILES])\n",
    "\n",
    "    seen, out = set(), []\n",
    "    for p in tqdm(picked, desc=\"Deduplicating files\"):\n",
    "        if p not in seen:\n",
    "            seen.add(p)\n",
    "            out.append(p)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940adac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_repo_context(repo, tree):\n",
    "    repo_full = repo[\"full_name\"]\n",
    "    branch = get_default_branch(repo_full)\n",
    "\n",
    "    tree_items = [t for t in tree if t.get(\"type\") in (\"blob\", \"tree\")]\n",
    "    tree_items = tree_items[:MAX_TREE_ITEMS]\n",
    "\n",
    "    paths = [t[\"path\"] for t in tree_items if \"path\" in t]\n",
    "    files = [p for p in paths if not is_probably_binary(p)]\n",
    "\n",
    "    chosen = pick_key_files(files)\n",
    "\n",
    "    file_blobs = []\n",
    "    for p in chosen:\n",
    "        try:\n",
    "            txt = fetch_file_text(repo_full, p, branch)\n",
    "            if txt.strip():\n",
    "                file_blobs.append({\"path\": p, \"text\": txt})\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    meta = {\n",
    "        \"name\": repo.get(\"name\"),\n",
    "        \"full_name\": repo_full,\n",
    "        \"description\": repo.get(\"description\"),\n",
    "        \"topics\": repo.get(\"topics\", []),\n",
    "        \"default_branch\": branch,\n",
    "        \"language\": repo.get(\"language\"),\n",
    "        \"updated_at\": repo.get(\"updated_at\"),\n",
    "        \"stargazers\": repo.get(\"stargazers_count\"),\n",
    "        \"forks\": repo.get(\"forks_count\"),\n",
    "        \"open_issues\": repo.get(\"open_issues_count\"),\n",
    "        \"license\": (repo.get(\"license\") or {}).get(\"spdx_id\"),\n",
    "        \"html_url\": repo.get(\"html_url\"),\n",
    "    }\n",
    "    return meta, paths, file_blobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5452f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(meta, paths, file_blobs):\n",
    "    tree_preview = \"\\n\".join(paths[:600])\n",
    "\n",
    "    def fence(path, text):\n",
    "        ext = pathlib.Path(path).suffix.lstrip(\".\")\n",
    "        lang = ext if ext else \"\"\n",
    "        text = text[:MAX_FILE_CHARS]\n",
    "        return f\"### {path}\\n```{lang}\\n{text}\\n```\\n\"\n",
    "\n",
    "    snippets = \"\\n\".join(fence(f[\"path\"], f[\"text\"]) for f in file_blobs[:20])\n",
    "\n",
    "    return f\"\"\"\n",
    "You are a senior engineer writing documentation.\n",
    "\n",
    "Generate a SINGLE markdown document that explains this GitHub repository clearly.\n",
    "Use proper headings and subheadings and keep it accurate based only on provided data.\n",
    "If something is unclear, say so.\n",
    "\n",
    "# Required structure\n",
    "- Title with repo name\n",
    "- Overview (what it is, who it's for)\n",
    "- Key Features (bullets)\n",
    "- Architecture / How it works (based on files/config)\n",
    "- Notable folders/files (explain why they matter)\n",
    "- Setup & Run (infer from configs; include commands if obvious)\n",
    "- How to use (examples if you can infer)\n",
    "- Testing / CI (if present)\n",
    "- Deployment (if present)\n",
    "- Contribution notes (if present)\n",
    "- Limitations / TODOs you infer (clearly labeled as inference)\n",
    "\n",
    "# Repo metadata (JSON)\n",
    "{json.dumps(meta, indent=2)}\n",
    "\n",
    "# File tree (preview)\n",
    "{tree_preview}\n",
    "\n",
    "# File excerpts\n",
    "{snippets}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70deceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_filename(name: str) -> str:\n",
    "    \"\"\"Replace invalid filename characters with underscores.\"\"\"\n",
    "    name = re.sub(r\"[^a-zA-Z0-9._-]+\", \"_\", name).strip(\"_\")\n",
    "    return name or \"repo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e92c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_markdown_with_openai(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate markdown documentation using OpenAI SDK with OSS model.\n",
    "    \"\"\"\n",
    "    if not OPENAI_API_KEY:\n",
    "        raise RuntimeError(\"OPENAI_API_KEY is missing. Set it in your environment.\")\n",
    "\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You write high-quality repo documentation in Markdown.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=4096,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f109cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_repo(repo):\n",
    "    \"\"\"\n",
    "    Worker function executed in a separate process.\n",
    "    Must be top-level (picklable) for Windows/macOS spawn.\n",
    "    \"\"\"\n",
    "    repo_full = repo[\"full_name\"]\n",
    "    try:\n",
    "        branch = get_default_branch(repo_full)\n",
    "        tree = get_repo_tree(repo_full, branch)\n",
    "        meta, paths, file_blobs = build_repo_context(repo, tree)\n",
    "        prompt = make_prompt(meta, paths, file_blobs)\n",
    "        md = generate_markdown_with_openai(prompt)\n",
    "\n",
    "        out_path = OUT_DIR / f\"{safe_filename(repo['name'])}.md\"\n",
    "        header = f\"<!-- Generated: {datetime.utcnow().isoformat()}Z | Model: {MODEL_NAME} -->\\n\\n\"\n",
    "        out_path.write_text(header + md.strip() + \"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "        return {\"repo\": repo_full, \"ok\": True, \"path\": str(out_path)}\n",
    "    except Exception as e:\n",
    "        return {\"repo\": repo_full, \"ok\": False, \"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebe2c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Fetch all repos and process in parallel with progress tracking.\"\"\"\n",
    "    if not GITHUB_USERNAME:\n",
    "        raise RuntimeError(\"Set GITHUB_USERNAME in env.\")\n",
    "\n",
    "    repos = list_repos(GITHUB_USERNAME)\n",
    "    print(f\"Found {len(repos)} repos for @{GITHUB_USERNAME}\")\n",
    "\n",
    "    for res in tqdm(repos, desc=\"Processing repositories\"):\n",
    "        res = process_one_repo(res)\n",
    "        if res[\"ok\"]:\n",
    "            print(f\"✅ {res['repo']} -> {res['path']}\")\n",
    "        else:\n",
    "            print(f\"⚠️ {res['repo']} failed: {res['error']}\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75a5728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faad7d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-rag-private-knowledge-worker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
